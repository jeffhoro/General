{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition Details\n",
    "Welcome to the Amazon Reviews Recommender System Challenge! Your goal is to develop an accurate recommender system using any approach you prefer. You will train your model using Amazon product reviews and predict missing ratings for a hidden test set. Your predictions will be evaluated automatically on Kaggle, and you will be ranked based on Root Mean Squared Error (RMSE).\n",
    "\n",
    "This is an open-ended competition where you can use any technique to improve your model’s accuracy, including collaborative filtering, matrix factorization, deep learning, or hybrid approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "We will use a subset of the Amazon Review dataset, which contains user-product ratings from the Electronics category.\n",
    "Dataset Information:\n",
    "\n",
    "\n",
    "*   UserID\n",
    "*   ItemID\n",
    "*   User-product ratings (1 to 5 stars)\n",
    "\n",
    "For this challenge, you will be working with training and test datasets:\n",
    "\n",
    "\n",
    "*   train_ratings.csv → Contains 80% of known ratings for training\n",
    "*   test_ratings.csv → Contains 20% missing ratings, which you must predict\n",
    "*   sample_submission.csv → A sample submission file to guide you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Description\n",
    "You are free to choose any approach to build your recommendation model, including Collaborative Filtering, Matrix Factorization, Deep Learning, and Hybrid Approaches. Feel free to use any techniques, methodologies, and approaches you want. In order to predict the missing ratings, you should train your model on train_ratings.csv and predict all missing ratings in test_ratings.csv. Then, you should also save your predictions in the required Kaggle submission format (please see the sample submission file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Evaluation is based on the final performance achieved by your best-reported model at the end of the competition.\n",
    "\n",
    "Kaggle Link: https://www.kaggle.com/t/fb24fd522c3e43da9775a01b7979c901"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 1.1390\n",
      "Epoch 2/15, Loss: 1.2778\n",
      "Epoch 3/15, Loss: 1.1693\n",
      "Epoch 4/15, Loss: 0.9178\n",
      "Epoch 5/15, Loss: 0.7088\n",
      "Epoch 6/15, Loss: 0.6887\n",
      "Epoch 7/15, Loss: 0.6373\n",
      "Epoch 8/15, Loss: 0.6106\n",
      "Epoch 9/15, Loss: 0.5280\n",
      "Epoch 10/15, Loss: 0.4506\n",
      "Epoch 11/15, Loss: 0.3895\n",
      "Epoch 12/15, Loss: 0.4268\n",
      "Epoch 13/15, Loss: 0.4582\n",
      "Epoch 14/15, Loss: 0.2756\n",
      "Epoch 15/15, Loss: 0.4089\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "# Amazon Reviews Recommender Systems Challenge Final Model\n",
    "# Submitted by: Jeff Horowitz\n",
    "\n",
    "# Hybrid Model Consisting of SVD, BaselineOnly, and NCF\n",
    "# Test RMSE = 0.884 trained on full training dataset\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from surprise import SVD, Dataset, Reader, BaselineOnly\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 1392\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv('train_amazon_ratings.csv')\n",
    "test = pd.read_csv('test_amazon_ratings.csv')\n",
    "\n",
    "# Load data into format for Surprice library models\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(train[['UserID', 'ItemID', 'Rating']], reader)\n",
    "\n",
    "# Split for validation (90% train, 10% test)\n",
    "#trainset, valset = train_test_split(data, test_size=0.10, random_state=SEED)\n",
    "\n",
    "# Train on full dataset for better performance before submission\n",
    "trainset = data.build_full_trainset() \n",
    "\n",
    "# --- SVD Model --- #\n",
    "# Train the SVD model\n",
    "svd_model = SVD(\n",
    "    n_factors=10,\n",
    "    lr_all=0.01,\n",
    "    reg_all=0.2,\n",
    "    n_epochs=12,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "# Define the SVD prediction function\n",
    "def svd_predict(user_id, item_id):\n",
    "    return svd_model.predict(user_id, item_id).est\n",
    "\n",
    "# --- NCF Model --- #\n",
    "# Prepare data for PyTorch\n",
    "user_ids = train['UserID'].unique()\n",
    "item_ids = train['ItemID'].unique()\n",
    "n_users = len(user_ids)\n",
    "n_items = len(item_ids)\n",
    "\n",
    "# Map IDs to indices\n",
    "user_to_idx = {uid: idx for idx, uid in enumerate(user_ids)}\n",
    "item_to_idx = {iid: idx for idx, iid in enumerate(item_ids)}\n",
    "\n",
    "# Convert training data to tensors\n",
    "train_users = torch.tensor([user_to_idx[uid] for uid in train['UserID']], dtype=torch.long)\n",
    "train_items = torch.tensor([item_to_idx[iid] for iid in train['ItemID']], dtype=torch.long)\n",
    "train_ratings = torch.tensor(train['Rating'].values, dtype=torch.float32)\n",
    "\n",
    "# Define NCF model architecture\n",
    "# This is a simple NCF model with two hidden layers with a ReLU activation function and dropout after each layer\n",
    "# The embedding dimension is set to 8, and the model is trained with Adam optimizer and MSE loss function\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=8):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(n_items, embedding_dim)\n",
    "\n",
    "        self.fc1 = nn.Linear(embedding_dim * 2, 64)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)  # Dropout layer\n",
    "\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)  # Dropout layer\n",
    "\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        user_emb = self.user_embedding(users)\n",
    "        item_emb = self.item_embedding(items)\n",
    "        x = torch.cat([user_emb, item_emb], dim=-1)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.output(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "# Initialize and train NCF\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ncf_model = NCF(n_users, n_items, embedding_dim=8).to(device)\n",
    "optimizer = optim.Adam(ncf_model.parameters(), lr=0.002, weight_decay=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 15\n",
    "batch_size = 64\n",
    "ncf_model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(train_users), batch_size):\n",
    "        batch_users = train_users[i:i+batch_size].to(device)\n",
    "        batch_items = train_items[i:i+batch_size].to(device)\n",
    "        batch_ratings = train_ratings[i:i+batch_size].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = ncf_model(batch_users, batch_items)\n",
    "        loss = criterion(predictions, batch_ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# NCF prediction function\n",
    "def ncf_predict(user_id, item_id):\n",
    "    ncf_model.eval()\n",
    "    with torch.no_grad():\n",
    "        user_idx = torch.tensor([user_to_idx.get(user_id, 0)], dtype=torch.long).to(device)\n",
    "        item_idx = torch.tensor([item_to_idx.get(item_id, 0)], dtype=torch.long).to(device)\n",
    "        pred = ncf_model(user_idx, item_idx).cpu().item()\n",
    "    return pred\n",
    "\n",
    "# --- BaselineOnly Model --- #\n",
    "# Train the BaselineOnly model\n",
    "baseline_model = BaselineOnly(bsl_options={\n",
    "    'method': 'als',\n",
    "    'n_epochs': 20,\n",
    "    'reg_u': 0.3,\n",
    "    'reg_i': 0.3\n",
    "})\n",
    "\n",
    "baseline_model.fit(trainset)\n",
    "\n",
    "# Define the Baseline prediction function\n",
    "def baseline_predict(user_id, item_id):\n",
    "    return baseline_model.predict(user_id, item_id).est\n",
    "\n",
    "# --- Hybrid Prediction Function with Capping --- #\n",
    "# Define the model weights\n",
    "weight_svd = 0.9\n",
    "weight_ncf = 0.05\n",
    "weight_baseline = 0.05\n",
    "\n",
    "# Define the hybrid prediction function\n",
    "def hybrid_predict(user_id, item_id):\n",
    "    svd_pred = svd_predict(user_id, item_id)\n",
    "    ncf_pred = ncf_predict(user_id, item_id)\n",
    "    baseline_pred = baseline_predict(user_id, item_id)\n",
    "    hybrid_rating = (weight_svd * svd_pred) + (weight_ncf * ncf_pred) + (weight_baseline * baseline_pred)\n",
    "    # Cap predictions between 1 and 5\n",
    "    return max(1, min(5, hybrid_rating))\n",
    "\n",
    "# Uncomment the entire block below to run the hybrid model on the validation set without submission to Kaggle\n",
    "# This block is commented out to avoid running it during the submission process\n",
    "# This block calculates validation RMSE to allow for hyperparameter tuning and model evaluation\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------- #\n",
    "# --- Validation RMSEs --- #\n",
    "# #SVD predictions on validation set\n",
    "# svd_predictions = svd_model.test(valset)\n",
    "# baseline_predictions = baseline_model.test(valset)\n",
    "\n",
    "# # NCF predictions on validation set\n",
    "# ncf_model.eval()\n",
    "# val_users = torch.tensor([user_to_idx.get(uid, 0) for uid, _, _ in valset], dtype=torch.long).to(device)\n",
    "# val_items = torch.tensor([item_to_idx.get(iid, 0) for _, iid, _ in valset], dtype=torch.long).to(device)\n",
    "# with torch.no_grad():\n",
    "#     ncf_ratings = ncf_model(val_users, val_items).cpu().numpy()\n",
    "\n",
    "# # Hybrid predictions on validation set with capping\n",
    "# hybrid_predictions = []\n",
    "# for svd_pred, ncf_rating, baseline_pred in zip(svd_predictions, ncf_ratings, baseline_predictions):\n",
    "#     hybrid_rating = (weight_svd * svd_pred.est) + (weight_ncf * ncf_rating) + (weight_baseline * baseline_pred.est)\n",
    "#     # Cap hybrid predictions between 1 and 5\n",
    "#     capped_hybrid_rating = max(1, min(5, hybrid_rating))\n",
    "#     hybrid_pred = svd_pred._replace(est=capped_hybrid_rating)\n",
    "#     hybrid_predictions.append(hybrid_pred)\n",
    "\n",
    "# # Calculate and print RMSEs\n",
    "# print(\"\\nValidation Results:\")\n",
    "# hybrid_rmse = accuracy.rmse(hybrid_predictions, verbose=False)\n",
    "# print(f\"Hybrid RMSE: {hybrid_rmse}\")\n",
    "# ---------------------------------------------------------------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file saved as submission_SVD_NCF_Baseline.csv\n"
     ]
    }
   ],
   "source": [
    "# Use this code to generate a submission file for Kaggle in the correct format\n",
    "# Define file generation function\n",
    "def generate_submission_file(model_function, test_data, filename=\"submission.csv\"):\n",
    "    \"\"\"Generate a submission file for Kaggle.\"\"\"\n",
    "    submission_data = []\n",
    "\n",
    "    for _, row in test_data.iterrows():\n",
    "        id, user_id, item_id = row['id'], row['UserID'], row['ItemID']\n",
    "        predicted_rating = model_function(user_id, item_id)\n",
    "        submission_data.append([id, predicted_rating])\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_data, columns=[\"id\", \"PredictedRating\"])\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    print(f\"✅ Submission file saved as {filename}\")\n",
    "\n",
    "# Call function to generate submission file\n",
    "generate_submission_file(hybrid_predict, test, filename=\"submission_SVD_NCF_Baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
